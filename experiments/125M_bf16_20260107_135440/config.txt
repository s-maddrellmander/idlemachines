Model: 125M
Mode: bf16
Steps: 1335
Batch size per GPU: 64
Gradient accumulation: 32
World size: 1
Sequence length: 1024
Effective batch: 2048
Tokens per step: 2097152
Total tokens: 2.79B
Learning rate: 3e-4 â†’ 3e-5
Warmup fraction: 0.02
Validation every: 500
Started: Wed Jan  7 13:54:40 UTC 2026
Completed: Wed Jan  7 15:58:48 UTC 2026
